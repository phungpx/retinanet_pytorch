data:
  test:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: flame.core.data.coco_dataset
        class: CoCoDataset
        CoCoDataset:
          imsize: 768
          image_dir: '''/extdata/ocr/phungpx/projects/PHUNGPX/object_detection_pytorch/efficient_det_pytorch/dataset/birdview_vehicles/val'''
          label_path: '''/extdata/ocr/phungpx/projects/PHUNGPX/object_detection_pytorch/efficient_det_pytorch/dataset/birdview_vehicles/annotations/instances_val.json'''
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
      batch_size: 1
      shuffle: False
      drop_last: False
      pin_memory: True
      num_workers: 12
      collate_fn: 'lambda batch:tuple(zip(*batch))'

model:
  module: flame.core.model.retina_net
  class: Model
  Model:
    num_classes: 2
    backbone_name: '''resnet50'''
    backbone_pretrained: False
    scales: ['2 ** 0', '2 ** (1 / 3)', '2 ** (2 / 3)']
    aspect_ratios: [0.5, 1., 2.]  # anchor_width / anchor_height
    iou_threshold: 0.45
    score_threshold: 0.2

metrics:
  module: flame.handlers.metrics.metrics
  class: Metrics
  Metrics:
    metrics:
      mAP:
        module: flame.handlers.metrics.evaluator
        class: Evaluator
        Evaluator:
          eval_fn:
            module: flame.core.metric.mAP
            class: MeanAveragePrecision
            MeanAveragePrecision:
              classes:
                large-vehicle: 0
                small-vehicle: 1
              iou_threshold: 0.5
              method: '''every_point_interpolation'''
              print_FP_files: False
          output_transform: 'lambda x: (x[0], x[1], x[2])'
      coco_eval:
        module: flame.core.metric.COCO_eval
        class: COCOEvaluator
        COCOEvaluator:
          imsize: 768
          # annotation_file: '''/extdata/ocr/phungpx/projects/PHUNGPX/object_detection_pytorch/efficient_det_pytorch/dataset/birdview_vehicles/annotations/instances_val.json'''
          detection_path: '''checkpoint/birdview_vehicles/retinanet_resnet50_fpn/2205161330/birdview_vehicles_det_val.json'''
          ground_truth_path: '''checkpoint/birdview_vehicles/retinanet_resnet50_fpn/2205161330/birdview_vehicles_gt_val.json'''
          classes: 2
          output_transform: 'lambda x: (x[0], x[1], x[2])'
    attach_to:
      engine: '''test'''

screenlogger:
  module: flame.handlers.screenlogger
  class: ScreenLogger
  ScreenLogger:
    eval_names:
      - '''test'''

checkpoint_loader:
  module: flame.handlers.checkpoint
  class: CheckpointLoader
  CheckpointLoader:
    checkpoint_path: '''checkpoint/birdview_vehicles/retinanet_resnet50_fpn/2205161330/best_model_168_focal_loss=-12.7966.pt'''
    mode: '''test'''

predictor:
  module: flame.handlers.region_predictor
  class: RegionPredictor
  RegionPredictor:
    evaluator_name: '''engine'''
    output_dir: '''checkpoint/birdview_vehicles/retinanet_resnet50_fpn/2205161330/best_model_168_focal_loss=-12.7966'''
    imsize: 768
    classes:
      large-vehicle: [[255, 0, 0], 0]  # color, class_idx, area_threshold
      small-vehicle: [[0, 255, 0], 1]
    output_transform: 'lambda x: (x[0], x[-1])'

engine:
  module: flame.core.engine.evaluator
  class: Evaluator
  Evaluator:
    dataset: config['data']['test']
    device: '''cuda'''

extralibs:
  torch: torch
