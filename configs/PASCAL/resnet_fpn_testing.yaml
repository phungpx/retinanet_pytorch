data:
  test:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: flame.core.data.pascal_dataset
        class: PascalDataset
        PascalDataset:
          VOC2012:
            image_dir: '''/extdata/ocr/phungpx/projects/PHUNGPX/object_detection_pytorch/efficient_det_pytorch/dataset/PASCALVOC2012/JPEGImages/'''
            label_dir: '''/extdata/ocr/phungpx/projects/PHUNGPX/object_detection_pytorch/efficient_det_pytorch/dataset/PASCALVOC2012/Annotations/'''
            txt_path: '''/extdata/ocr/phungpx/projects/PHUNGPX/object_detection_pytorch/efficient_det_pytorch/dataset/PASCALVOC2012/ImageSets/Segmentation/val.txt'''
          VOC2007:
            image_dir: '''/extdata/ocr/phungpx/projects/PHUNGPX/object_detection_pytorch/efficient_det_pytorch/dataset/PASCALVOC2007/VOCtest_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages/'''
            label_dir: '''/extdata/ocr/phungpx/projects/PHUNGPX/object_detection_pytorch/efficient_det_pytorch/dataset/PASCALVOC2007/VOCtest_06-Nov-2007/VOCdevkit/VOC2007/Annotations/'''
          image_extent: '''.jpg'''
          label_extent: '''.xml'''
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
          imsize: 896
          classes:
            aeroplane: 0
            bicycle: 1
            bird: 2
            boat: 3
            bottle: 4
            bus: 5
            car: 6
            cat: 7
            chair: 8
            cow: 9
            diningtable: 10
            dog: 11
            horse: 12
            motorbike: 13
            person: 14
            pottedplant: 15
            sheep: 16
            sofa: 17
            train: 18
            tvmonitor: 19
      batch_size: 4
      shuffle: False
      pin_memory: True
      num_workers: 12
      drop_last: False
      collate_fn: 'lambda batch:tuple(zip(*batch))'

model:
  module: flame.core.model.retina_net
  class: Model
  Model:
    num_classes: 20
    backbone_name: '''resnet50'''
    backbone_pretrained: False
    scales: ['2 ** 0', '2 ** (1 / 3)', '2 ** (2 / 3)']
    aspect_ratios: [0.25, 0.5, 1., 2., 4. ]  # anchor_width / anchor_height
    iou_threshold: 0.5
    score_threshold: 0.02

metrics:
  module: flame.handlers.metrics.metrics
  class: Metrics
  Metrics:
    metrics:
      mAP:
        module: flame.handlers.metrics.evaluator
        class: Evaluator
        Evaluator:
          eval_fn:
            module: flame.core.metric.mAP
            class: MeanAveragePrecision
            MeanAveragePrecision:
              classes:
                aeroplane: 0
                bicycle: 1
                bird: 2
                boat: 3
                bottle: 4
                bus: 5
                car: 6
                cat: 7
                chair: 8
                cow: 9
                diningtable: 10
                dog: 11
                horse: 12
                motorbike: 13
                person: 14
                pottedplant: 15
                sheep: 16
                sofa: 17
                train: 18
                tvmonitor: 19
              iou_threshold: 0.5
              method: '''every_point_interpolation'''
              print_FP_files: False
          output_transform: 'lambda x: (x[0], x[1], x[2])'
      coco_eval:
        module: flame.core.metric.COCO_eval
        class: COCOEvaluator
        COCOEvaluator:
          imsize: 896
          detection_path: '''checkpoint/PASCAL/resnet50/2205161702/PASCAL_det_val.json'''
          ground_truth_path: '''checkpoint/PASCAL/resnet50/2205161702/PASCAL_gt_val.json'''
          classes: 20
          output_transform: 'lambda x: (x[0], x[1], x[2])'
    attach_to:
      engine: '''test'''

screenlogger:
  module: flame.handlers.screenlogger
  class: ScreenLogger
  ScreenLogger:
    eval_names:
      - '''test'''

checkpoint_loader:
  module: flame.handlers.checkpoint
  class: CheckpointLoader
  CheckpointLoader:
    checkpoint_path: '''checkpoint/PASCAL/resnet50/2205161702/best_model_190_focal_loss=-21.9277.pt'''
    mode: '''test'''

predictor:
  module: flame.handlers.region_predictor
  class: RegionPredictor
  RegionPredictor:
    evaluator_name: '''engine'''
    output_dir: '''checkpoint/PASCAL/resnet50/2205161702/best_model_190_focal_loss=-21.9277'''
    imsize: 896
    classes:
      aeroplane: [[128, 0, 0], 0]  # color, class_idx, area_threshold
      bicycle: [[0, 128, 0], 1]
      bird: [[128, 128, 0], 2]
      boat: [[0, 0, 128], 3]
      bottle: [[128, 0, 128], 4]
      bus: [[0, 128, 128], 5]
      car: [[128, 128, 128], 6]
      cat: [[64, 0, 0], 7]
      chair: [[192, 0, 0], 8]
      cow: [[64, 128, 0], 9]
      diningtable: [[192, 128, 0], 10]
      dog: [[64, 0, 128], 11]
      horse: [[192, 0, 128], 12]
      motorbike: [[64, 128, 128], 13]
      person: [[192, 128, 128], 14]
      pottedplant: [[0, 64, 0], 15]
      sheep: [[128, 64, 0], 16]
      sofa: [[0, 192, 0], 17]
      train: [[128, 192, 0], 18]
      tvmonitor: [[0, 64, 128], 19]
    output_transform: 'lambda x: (x[0], x[-1])'

engine:
  module: flame.core.engine.evaluator
  class: Evaluator
  Evaluator:
    dataset: config['data']['test']
    device: '''cuda'''

extralibs:
  torch: torch
